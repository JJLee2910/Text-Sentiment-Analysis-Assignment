{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. Work on sentence probabilities (14 marks)\n",
    "\n",
    "Use the Data_3.txt given in the Assignment Data.zip to Carry out the following tasks. The file Data_3.txt is a text corpus which contains three sentences. Each sentence is limited by the sentence pads such as \\<s> and \\</s> as the starting and end of the sentence respectively. You are expected to use the appropriate equations to perform the respective tasks.\n",
    "\n",
    "Perform suitable pre-processing if required.\n",
    "1.\tCompute manually the sentences probabilities using the unsmoothed bigram model. (4 marks)\n",
    "2.\tCompute manually the sentences probabilities using the smoothed bigram model. (4 marks)\n",
    "3.\tImplement in python using both unsmoothed and smoothed bigram language models and report the respective sentence probabilities. (6 marks)\n",
    "\n",
    "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 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Courpus:  ['he read a book', 'i read a different book', 'he read a book by danielle']\n",
      "Training Sentence:  i read a book by danielle\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.util import pad_sequence\n",
    "from nltk.util import bigrams\n",
    "from nltk.util import ngrams\n",
    "from nltk.util import everygrams\n",
    "from nltk.lm.preprocessing import pad_both_ends\n",
    "from nltk.lm.preprocessing import flatten\n",
    "\n",
    "\n",
    "# Open the text corpus\n",
    "with open(\"Assignment Data/Data_3.txt\", \"r\") as file:\n",
    "    # Open an empty list to store lines starting with \"<\"\n",
    "    usable_line = []\n",
    "\n",
    "    # loop through each line in the file\n",
    "    for line in file:\n",
    "        # Check if the line starts with \"<\"\n",
    "        if line.startswith(\"<\"):\n",
    "            procesed_line = line.replace(\"<s>\", \"\").replace(\"</s>\", \"\").lower() #preprocess the line to lower and remove character\n",
    "            # If it does, append it to the list\n",
    "            usable_line.append(procesed_line.strip())  # Strip to remove leading/trailing whitespace\n",
    "        else:\n",
    "            # If it doesn't start with \"<\", move to the next line\n",
    "            continue\n",
    "file.close()\n",
    "\n",
    "# differenciate the sentece to text corpus and targetted sentences\n",
    "corpus = usable_line[:-1]\n",
    "traning = usable_line [-1]\n",
    "\n",
    "print(\"Text Courpus: \" , corpus)\n",
    "print(\"Training Sentence: \" , traning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', 'he', 'read', 'a', 'book', '</s>', '<s>', 'i', 'read', 'a', 'different', 'book', '</s>', '<s>', 'he', 'read', 'a', 'book', 'by', 'danielle', '</s>']\n",
      "[('<s>', 'he'), ('he', 'read'), ('read', 'a'), ('a', 'book'), ('book', '</s>'), ('<s>', 'i'), ('i', 'read'), ('read', 'a'), ('a', 'different'), ('different', 'book'), ('book', '</s>'), ('<s>', 'he'), ('he', 'read'), ('read', 'a'), ('a', 'book'), ('book', 'by'), ('by', 'danielle'), ('danielle', '</s>')]\n"
     ]
    }
   ],
   "source": [
    "freqeuncy_corpus = []\n",
    "final_corpus = []\n",
    "\n",
    "def bigram(x):\n",
    "    tokenized_corpus = nltk.tokenize.word_tokenize(x)\n",
    "    padded = list(pad_both_ends(tokenized_corpus, n=2))\n",
    "    freqeuncy_corpus.append(padded)\n",
    "    bigram_1 = list(bigrams(padded))\n",
    "    final_corpus.append(bigram_1)\n",
    "\n",
    "\n",
    "\n",
    "bigram(corpus[0])\n",
    "bigram(corpus[1])\n",
    "bigram(corpus[2])\n",
    "\n",
    "bigram_frequncy = sum(final_corpus, [])\n",
    "frequncy = sum(freqeuncy_corpus, [])\n",
    "\n",
    "print(frequncy)\n",
    "print(bigram_frequncy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens in the corpus = \n",
      " ['</s>', '<s>', 'different', 'he', 'danielle', 'i', 'read', 'a', 'by', 'book']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "distinct_tokens = list(set(sorted(frequncy)))\n",
    "print(\"Tokens in the corpus = \\n\",distinct_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('<s>', 'i'), ('i', 'read'), ('read', 'a'), ('a', 'book'), ('book', 'by'), ('by', 'danielle'), ('danielle', '</s>')]\n"
     ]
    }
   ],
   "source": [
    "#target sentence\n",
    "tokenized_corpus = nltk.tokenize.word_tokenize(traning)\n",
    "bigram_target = list(bigrams(pad_both_ends(tokenized_corpus, n=2)))\n",
    "print(bigram_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of each tokens = \n",
      "<s> \t: 3\n",
      "he \t: 2\n",
      "read \t: 3\n",
      "a \t: 3\n",
      "book \t: 3\n",
      "</s> \t: 3\n",
      "i \t: 1\n",
      "different \t: 1\n",
      "by \t: 1\n",
      "danielle \t: 1\n"
     ]
    }
   ],
   "source": [
    "def generate_tokens_freq(tokens):\n",
    "    dct={}\n",
    "    for i in tokens:\n",
    "        dct[i]=0\n",
    "    for i in tokens:\n",
    "        dct[i]+=1\n",
    "    return dct\n",
    "\n",
    "\n",
    "dct=generate_tokens_freq(frequncy)\n",
    "print(\"Frequency of each tokens = \")\n",
    "for i in dct.items():\n",
    "    print(i[0],\"\\t:\" , i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of each Bigram = \n",
      "('<s>', 'he') \t: 2\n",
      "('he', 'read') \t: 2\n",
      "('read', 'a') \t: 3\n",
      "('a', 'book') \t: 2\n",
      "('book', '</s>') \t: 2\n",
      "('<s>', 'i') \t: 1\n",
      "('i', 'read') \t: 1\n",
      "('a', 'different') \t: 1\n",
      "('different', 'book') \t: 1\n",
      "('book', 'by') \t: 1\n",
      "('by', 'danielle') \t: 1\n",
      "('danielle', '</s>') \t: 1\n"
     ]
    }
   ],
   "source": [
    "dct_1 =generate_tokens_freq(bigram_frequncy)\n",
    "print(\"Frequency of each Bigram = \")\n",
    "for i in dct_1.items():\n",
    "    print(i[0],\"\\t:\" , i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Bigrams along with their probability \n",
      "{('<s>', 'he'): 0.6666666666666666, ('he', 'read'): 1.0, ('read', 'a'): 1.0, ('a', 'book'): 0.6666666666666666, ('book', '</s>'): 0.6666666666666666, ('<s>', 'i'): 0.3333333333333333, ('i', 'read'): 1.0, ('a', 'different'): 0.3333333333333333, ('different', 'book'): 1.0, ('book', 'by'): 0.3333333333333333, ('by', 'danielle'): 1.0, ('danielle', '</s>'): 1.0}\n",
      "\n",
      "Unsmoothed probablility of sentence \"i read a book by danielle\" = 0.07407407407407407\n"
     ]
    }
   ],
   "source": [
    "def calcBigramProb(listOfBigrams, unigramCounts, bigramCounts):\n",
    "    listOfProb = {}\n",
    "    for bigram in listOfBigrams:\n",
    "        word1 = bigram[0]\n",
    "        word2 = bigram[1]\n",
    "        listOfProb[bigram] = (bigramCounts.get(bigram))/(unigramCounts.get(word1))\n",
    "    return listOfProb\n",
    "\n",
    "bigramProb = calcBigramProb(bigram_frequncy, dct, dct_1)\n",
    "\n",
    "print(\"\\n Bigrams along with their probability \")\n",
    "print(bigramProb)\n",
    "outputProb1 = 1\n",
    "\n",
    "for i in range(len(bigram_target)):\n",
    "    if bigram_target[i] in bigramProb:\n",
    "\n",
    "        outputProb1 = outputProb1 * bigramProb[bigram_target[i]]\n",
    "    else:\n",
    "\n",
    "         outputProb1 *= 0\n",
    "print('\\n' + 'Unsmoothed probablility of sentence \\\"i read a book by danielle\\\" = ' + str(outputProb1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Bigrams along with their probability \n",
      "{('<s>', 'he'): 0.23076923076923078, ('he', 'read'): 0.25, ('read', 'a'): 0.3076923076923077, ('a', 'book'): 0.23076923076923078, ('book', '</s>'): 0.23076923076923078, ('<s>', 'i'): 0.15384615384615385, ('i', 'read'): 0.18181818181818182, ('a', 'different'): 0.15384615384615385, ('different', 'book'): 0.18181818181818182, ('book', 'by'): 0.15384615384615385, ('by', 'danielle'): 0.18181818181818182, ('danielle', '</s>'): 0.18181818181818182}\n",
      "\n",
      " Smoothed probablility of sentence \"i read a book by danielle\" = 0.0000101013579198\n"
     ]
    }
   ],
   "source": [
    "def calcBigramProb(listOfBigrams, unigramCounts, bigramCounts):\n",
    "    listOfProb = {}\n",
    "    for bigram in listOfBigrams:\n",
    "        word1 = bigram[0]\n",
    "        word2 = bigram[1]\n",
    "        listOfProb[bigram] = (bigramCounts.get(bigram) + 1)/(unigramCounts.get(word1) + 10)\n",
    "    return listOfProb\n",
    "\n",
    "bigramProb = calcBigramProb(bigram_frequncy, dct, dct_1)\n",
    "\n",
    "print(\"\\n Bigrams along with their probability \")\n",
    "print(bigramProb)\n",
    "outputProb1 = 1\n",
    "\n",
    "for i in range(len(bigram_target)):\n",
    "    if bigram_target[i] in bigramProb:\n",
    "\n",
    "        outputProb1 = outputProb1 * bigramProb[bigram_target[i]]\n",
    "    else:\n",
    "\n",
    "         outputProb1 *= 0\n",
    "print('\\n' , 'Smoothed probablility of sentence \\\"i read a book by danielle\\\" =' , \"{:.16f}\".format(float(outputProb1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
