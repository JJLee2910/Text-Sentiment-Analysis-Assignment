{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. Form Parts of Speech (POS) taggers & Syntactic Analysers (12 marks) - JJ\n",
    "1.\tDemonstrate POS tagging using NLTK POS tagger, textblob POS tagger and the Regular Expression tagger and report the output. (5 marks)\n",
    "2.\tExplain the differences of the POS taggers using the output obtained in the above question. (2 marks)\n",
    "3.\tDraw possible parse trees for the given sentence using suitable python codes and report the output along with the code. (5 marks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK POS tagging:\n",
      "[('The', 'DT'), ('big', 'JJ'), ('black', 'JJ'), ('dog', 'NN'), ('barked', 'VBD'), ('at', 'IN'), ('the', 'DT'), ('white', 'JJ'), ('cat', 'NN'), ('and', 'CC'), ('chased', 'VBD'), ('away', 'RB'), ('.', '.')]\n",
      "\n",
      "TextBlob POS tagging:\n",
      "[('The', 'DT'), ('big', 'JJ'), ('black', 'JJ'), ('dog', 'NN'), ('barked', 'VBD'), ('at', 'IN'), ('the', 'DT'), ('white', 'JJ'), ('cat', 'NN'), ('and', 'CC'), ('chased', 'VBD'), ('away', 'RB')]\n",
      "\n",
      "Regular Expression tagging:\n",
      "[('The', 'NN'), ('big', 'NN'), ('black', 'NN'), ('dog', 'NN'), ('barked', 'VBD'), ('at', 'NN'), ('the', 'NN'), ('white', 'NN'), ('cat', 'NN'), ('and', 'NN'), ('chased', 'VBD'), ('away', 'NN'), ('.', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "# 1. Demonstrate POS tagging using NLTK POS tagger, textblob POS tagger and the Regular Expression tagger and report the output. (5 marks)\n",
    "\n",
    "# Import necessary library\n",
    "from nltk import pos_tag, RegexpTagger, word_tokenize\n",
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "# read data from text file\n",
    "with open('Assignment Data/Data_2.txt', 'r') as file:\n",
    "    line = file.read()\n",
    "\n",
    "# NLTK POS tagging\n",
    "nltk_tag = pos_tag(word_tokenize(line))\n",
    "\n",
    "# TextBlob POS tagging\n",
    "tb_tag = TextBlob(line).tags\n",
    "\n",
    "# Define Regular Expression tags\n",
    "patterns = [\n",
    "    (r'.*ed$', 'VBD'), # past tense verb\n",
    "    (r'.*es$', 'VBZ'), # present tense verb\n",
    "    (r'.*ing$', 'VBG'), # gerund\n",
    "    (r'.*ly$', 'RB'), # adverb\n",
    "    (r'.*s$', 'NNS'), # plural noun\n",
    "    (r'.*ful$', 'JJ'), # adjective\n",
    "    (r'.*', 'NN') # default noun\n",
    "]\n",
    "\n",
    "regex_tagger = RegexpTagger(patterns)\n",
    "regex_tags = regex_tagger.tag(word_tokenize(line))\n",
    "\n",
    "# Print the results\n",
    "print(\"NLTK POS tagging:\")\n",
    "print(nltk_tag)\n",
    "\n",
    "print(\"\\nTextBlob POS tagging:\")\n",
    "print(tb_tag)\n",
    "\n",
    "print(\"\\nRegular Expression tagging:\")\n",
    "print(regex_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'big', 'black', 'dog', 'barked', 'at', 'the', 'white', 'cat', 'and', 'chased', 'away', '.']\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Grammar does not cover some of the input words: \"'.'\".",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[0;32m     23\u001b[0m parser \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mChartParser(text2)\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tree \u001b[38;5;129;01min\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mparse(text1):\n\u001b[0;32m     25\u001b[0m     display(tree)\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28mprint\u001b[39m(tree)\n",
      "File \u001b[1;32mc:\\Users\\JJ\\anaconda3\\envs\\JJ\\Lib\\site-packages\\nltk\\parse\\chart.py:1474\u001b[0m, in \u001b[0;36mChartParser.parse\u001b[1;34m(self, tokens, tree_class)\u001b[0m\n\u001b[0;32m   1473\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m, tokens, tree_class\u001b[38;5;241m=\u001b[39mTree):\n\u001b[1;32m-> 1474\u001b[0m     chart \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchart_parse(tokens)\n\u001b[0;32m   1475\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28miter\u001b[39m(chart\u001b[38;5;241m.\u001b[39mparses(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_grammar\u001b[38;5;241m.\u001b[39mstart(), tree_class\u001b[38;5;241m=\u001b[39mtree_class))\n",
      "File \u001b[1;32mc:\\Users\\JJ\\anaconda3\\envs\\JJ\\Lib\\site-packages\\nltk\\parse\\chart.py:1432\u001b[0m, in \u001b[0;36mChartParser.chart_parse\u001b[1;34m(self, tokens, trace)\u001b[0m\n\u001b[0;32m   1429\u001b[0m trace_new_edges \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trace_new_edges\n\u001b[0;32m   1431\u001b[0m tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(tokens)\n\u001b[1;32m-> 1432\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_grammar\u001b[38;5;241m.\u001b[39mcheck_coverage(tokens)\n\u001b[0;32m   1433\u001b[0m chart \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_chart_class(tokens)\n\u001b[0;32m   1434\u001b[0m grammar \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_grammar\n",
      "File \u001b[1;32mc:\\Users\\JJ\\anaconda3\\envs\\JJ\\Lib\\site-packages\\nltk\\grammar.py:665\u001b[0m, in \u001b[0;36mCFG.check_coverage\u001b[1;34m(self, tokens)\u001b[0m\n\u001b[0;32m    663\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing:\n\u001b[0;32m    664\u001b[0m     missing \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mw\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m missing)\n\u001b[1;32m--> 665\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    666\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGrammar does not cover some of the \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput words: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m missing\n\u001b[0;32m    667\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Grammar does not cover some of the input words: \"'.'\"."
     ]
    }
   ],
   "source": [
    "# 3.Draw possible parse trees for the given sentence using suitable python codes and report the output along with the code. (5 marks)\n",
    "import nltk\n",
    "\n",
    "sentence = \"The big black dog barked at the white cat and chased away\"\n",
    "\n",
    "text2 = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP | S CC S\n",
    "NP -> Det NOM | Det N | NP CC NP | N | V P | PP NP | Det N PP\n",
    "NOM -> Adj NOM | Adj N | Adj Adj N | N\n",
    "VP -> V NP | VP PP | V | V NP PP | VP CC VP | Adj VP | VP Adj | V Adj\n",
    "PP -> P NP\n",
    "V -> 'barked' | 'chased'\n",
    "Det -> 'the' | 'The'\n",
    "CC -> 'and'\n",
    "N -> 'dog' | 'cat' | N CC N\n",
    "Adj -> 'big' | 'black' | 'white'\n",
    "P -> 'at' | 'away'\n",
    "\"\"\" )\n",
    "text1 = nltk.tokenize.word_tokenize(sentence)\n",
    "print(text1)\n",
    "print()\n",
    "parser = nltk.ChartParser(text2)\n",
    "for tree in parser.parse(text1):\n",
    "    display(tree)\n",
    "    print(tree)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JJ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
